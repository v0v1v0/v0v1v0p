<div class="container"><main><table style="width: 100%;"><tr>
<td>count_fields</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Count the number of fields in each line of a file</h2>

<h3>Description</h3>

<p>This is useful for diagnosing problems with functions that fail
to parse correctly.
</p>


<h3>Usage</h3>

<pre><code class="language-R">count_fields(file, tokenizer, skip = 0, n_max = -1L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr>
<td><code id="file">file</code></td>
<td>
<p>Either a path to a file, a connection, or literal data
(either a single string or a raw vector).
</p>
<p>Files ending in <code>.gz</code>, <code>.bz2</code>, <code>.xz</code>, or <code>.zip</code> will
be automatically uncompressed. Files starting with <code style="white-space: pre;"><U+2060>http://<U+2060></code>,
<code style="white-space: pre;"><U+2060>https://<U+2060></code>, <code style="white-space: pre;"><U+2060>ftp://<U+2060></code>, or <code style="white-space: pre;"><U+2060>ftps://<U+2060></code> will be automatically
downloaded. Remote gz files can also be automatically downloaded and
decompressed.
</p>
<p>Literal data is most useful for examples and tests. To be recognised as
literal data, the input must be either wrapped with <code>I()</code>, be a string
containing at least one new line, or be a vector containing at least one
string with a new line.
</p>
<p>Using a value of <code>clipboard()</code> will read from the system clipboard.</p>
</td>
</tr>
<tr>
<td><code id="tokenizer">tokenizer</code></td>
<td>
<p>A tokenizer that specifies how to break the <code>file</code>
up into fields, e.g., <code>tokenizer_csv()</code>,
<code>tokenizer_fwf()</code></p>
</td>
</tr>
<tr>
<td><code id="skip">skip</code></td>
<td>
<p>Number of lines to skip before reading data.</p>
</td>
</tr>
<tr>
<td><code id="n_max">n_max</code></td>
<td>
<p>Optionally, maximum number of rows to count fields for.</p>
</td>
</tr>
</table>
<h3>Examples</h3>

<pre><code class="language-R">count_fields(readr_example("mtcars.csv"), tokenizer_csv())
</code></pre>

</main></div>